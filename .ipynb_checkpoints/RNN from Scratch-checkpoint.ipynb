{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shatapy/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_size = 128\n",
    "element_size = 28\n",
    "time_size = 28\n",
    "batch_size = 128\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-39fa6a3b40ca>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/shatapy/anaconda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/shatapy/anaconda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shatapy/anaconda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shatapy/anaconda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shatapy/anaconda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, time_size, element_size], name='X')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_class], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('weights'):\n",
    "    Wx = tf.get_variable('Wx', [element_size, h_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wh = tf.get_variable('Wh', [h_size, h_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.Variable(tf.zeros([h_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_step(prev_h, x):\n",
    "    h = tf.tanh(\n",
    "        tf.matmul(prev_h, Wh) +\n",
    "        tf.matmul(x, Wx) + b\n",
    "    )\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = tf.transpose(X, perm=[1, 0, 2])  # now [time_size, batch_size, element_size]\n",
    "\n",
    "initial_hidden = tf.zeros([batch_size, h_size])\n",
    "all_h = tf.scan(rnn_step, X_, initializer=initial_hidden, name='all_states')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name = 'CEO of Google'\n",
    "name = [i for i in name]\n",
    "\n",
    "elems = np.array(name)\n",
    "scan_sum = tf.scan(lambda a, x:a+x, elems)  # elem\n",
    "\n",
    "def fn(x):\n",
    "    return x+'1'\n",
    "\n",
    "a = tf.map_fn(fn, scan_sum)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    Wl = tf.get_variable('Wl', [h_size, num_class], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     bl = tf.get_variable('bl', [num_class], initializer=tf.zeros_initializer())\n",
    "    bl = tf.Variable(tf.zeros([num_class]))\n",
    "    \n",
    "def get_linear_layer(h):\n",
    "    return tf.matmul(h, Wl) + bl\n",
    "    \n",
    "all_outputs = tf.map_fn(get_linear_layer, all_h)  # apply get_linear_layer fn to all_h\n",
    "output = all_outputs[-1]  # last outputs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-4f92011e4394>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = tf.equal(tf.argmax(output, 1), tf.argmax(Y, 1))\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_preds, tf.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0  Loss:  2.3884  Acc:  10.9375\n",
      "Iter:  1000  Loss:  2.2917638  Acc:  14.84375\n",
      "Iter:  2000  Loss:  2.1593409  Acc:  28.125\n",
      "Iter:  3000  Loss:  2.1386943  Acc:  28.125\n",
      "Iter:  4000  Loss:  2.05543  Acc:  35.15625\n",
      "Iter:  5000  Loss:  2.0147443  Acc:  32.8125\n",
      "Iter:  6000  Loss:  1.9073695  Acc:  35.15625\n",
      "Iter:  7000  Loss:  1.8846234  Acc:  39.84375\n",
      "Iter:  8000  Loss:  1.7671789  Acc:  42.1875\n",
      "Iter:  9000  Loss:  1.682164  Acc:  42.1875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape([batch_size, time_size, element_size])\n",
    "        \n",
    "        sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            acc, loss_ = sess.run([acc_op, loss], feed_dict={X:batch_x, Y:batch_y})\n",
    "            print('Iter: ', epoch, ' Loss: ', loss_, ' Acc: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
